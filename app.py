import streamlit as st
import google.generativeai as genai
from PIL import Image
import os
import time
import streamlit.components.v1 as components
import random
import re
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

# --- æ³¨å…¥è‡ªå®šç¾© CSS ---
def inject_custom_css():
    st.markdown(
        """
        <style>
        .katex-html { overflow-x: auto; overflow-y: hidden; max-width: 100%; display: block; padding-bottom: 5px; }
        .stMarkdown { max-width: 100%; overflow-wrap: break-word; }
        .stChatMessage .stChatMessageAvatar { background-color: #f0f2f6; color: #31333F; font-weight: bold; }
        </style>
        """,
        unsafe_allow_html=True,
    )

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI é³©ç‰¹è§£é¡Œ v4.1 Pro", page_icon="ğŸ¦", layout="centered")
inject_custom_css()

# --- åˆå§‹åŒ– Session State ---
if 'step_index' not in st.session_state: st.session_state.step_index = 0
if 'solution_steps' not in st.session_state: st.session_state.solution_steps = []
if 'is_solving' not in st.session_state: st.session_state.is_solving = False
if 'streaming_done' not in st.session_state: st.session_state.streaming_done = False
if 'in_qa_mode' not in st.session_state: st.session_state.in_qa_mode = False
if 'qa_history' not in st.session_state: st.session_state.qa_history = []
if 'solve_mode' not in st.session_state: st.session_state.solve_mode = "verbal"
if 'data_saved' not in st.session_state: st.session_state.data_saved = False
if 'plot_code' not in st.session_state: st.session_state.plot_code = None

# --- å‡½æ•¸å€ ---
def stream_text(text):
    for char in text:
        yield char
        time.sleep(0.02)

def trigger_vibration():
    vibrate_js = """<script>if(navigator.vibrate){navigator.vibrate(30);}</script>"""
    components.html(vibrate_js, height=0, width=0)

def save_to_google_sheets(grade, mode, image_desc, full_response):
    try:
        if "gcp_service_account" in st.secrets:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds_dict = dict(st.secrets["gcp_service_account"])
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
            creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(creds)
            sheet = client.open("Jutor_Learning_Data").sheet1
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            sheet.append_row([timestamp, grade, mode, image_desc, full_response])
            return True
    except Exception as e:
        print(f"å­˜æª”å¤±æ•—: {e}")
        return False

# --- åŸ·è¡Œ AI çµ¦çš„ç¹ªåœ–ç¨‹å¼ç¢¼ ---
def execute_and_show_plot(code_snippet):
    try:
        plt.figure(figsize=(6, 4))
        # è¨­å®šç¹ªåœ–é¢¨æ ¼
        plt.style.use('seaborn-v0_8-whitegrid') 
        local_scope = {'plt': plt, 'np': np}
        exec(code_snippet, globals(), local_scope)
        st.pyplot(plt)
        plt.close()
    except Exception as e:
        st.warning(f"åœ–å½¢ç¹ªè£½å¤±æ•— (ä»£ç¢¼éŒ¯èª¤): {e}")

# --- API å‘¼å« (æŒ‡å®šä½¿ç”¨ 2.5 Pro) ---
def call_gemini_with_rotation(prompt_content, image_input=None):
    try:
        keys = st.secrets["API_KEYS"]
        if isinstance(keys, str): keys = [keys]
    except:
        st.error("API_KEYS è¨­å®šéŒ¯èª¤")
        st.stop()
    
    shuffled_keys = keys.copy()
    random.shuffle(shuffled_keys)
    last_error = None
    
    for key in shuffled_keys:
        try:
            genai.configure(api_key=key)
            
            # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä½¿ç”¨æ‚¨æ¸…å–®ä¸­æœ€å¼·çš„ 2.5 Pro
            model = genai.GenerativeModel('models/gemini-2.5-pro')
            
            if image_input:
                response = model.generate_content([prompt_content, image_input])
            else:
                response = model.generate_content(prompt_content)
            return response
        except Exception as e:
            # å³ä½¿ä»˜è²»ï¼Œå¦‚æœæ˜¯ç¬æ™‚æµé‡éå¤§ (RPM)ï¼Œè¼ªæ›¿æ©Ÿåˆ¶é‚„æ˜¯å¾ˆæœ‰ç”¨çš„
            if "429" in str(e) or "Quota" in str(e) or "503" in str(e):
                last_error = e
                continue
            else:
                raise e
    raise last_error

# ================= ä»‹é¢è¨­è¨ˆ =================

col1, col2 = st.columns([1, 4]) 
with col1:
    if os.path.exists("logo.jpg"): st.image("logo.jpg", use_column_width=True)
    else: st.markdown("<h1 style='text-align: center;'>é³©</h1>", unsafe_allow_html=True)
with col2:
    st.title("é³©ç‰¹æ•¸ç†ï¼¡ï¼©å°å¹«æ‰‹")
    st.caption("AI é³©ç‰¹è§£é¡Œ v4.1 (2.5 Pro æ——è‰¦ç‰ˆ)")

st.markdown("---")
col_grade_label, col_grade_select = st.columns([2, 3])
with col_grade_label:
    st.markdown("### ğŸ“‹ è«‹å…ˆé¸æ“‡å¹´ç´šï¼š")
    st.caption("Jutor æœƒä¾æ­¤èª¿æ•´è¬›è§£å£å»ã€‚")
with col_grade_select:
    selected_grade = st.selectbox("å¹´ç´š", ("åœ‹ä¸€", "åœ‹äºŒ", "åœ‹ä¸‰", "é«˜ä¸€", "é«˜äºŒ", "é«˜ä¸‰"), label_visibility="collapsed")
st.markdown("---")

# --- ä¸Šå‚³å€ ---
if not st.session_state.is_solving:
    st.subheader("ğŸ“¸ 1ï¸âƒ£ ä¸Šå‚³é¡Œç›® & æŒ‡å®š")
    uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡ (JPG, PNG)", type=["jpg", "png", "jpeg"], label_visibility="collapsed")

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='é¡Œç›®é è¦½', use_column_width=True)
        question_target = st.text_input("ä½ æƒ³å•åœ–ç‰‡ä¸­çš„å“ªä¸€é¡Œï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šç¬¬ 5 é¡Œ...")
        
        st.markdown("### ğŸš€ é¸æ“‡è§£é¡Œæ¨¡å¼ï¼š")
        col_btn_verbal, col_btn_math = st.columns(2)
        with col_btn_verbal:
            start_verbal = st.button("ğŸ—£ï¸ Jutor å£èªæ•™å­¸", use_container_width=True, type="primary")
        with col_btn_math:
            start_math = st.button("ğŸ”¢ ç´”ç®—å¼è§£æ³•", use_container_width=True)

        if start_verbal or start_math:
            if not question_target:
                st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥ä½ æƒ³å•å“ªä¸€é¡Œï¼")
            else:
                mode = "verbal" if start_verbal else "math"
                st.session_state.solve_mode = mode
                loading_text = "Jutor Pro (2.5) æ­£åœ¨æ·±åº¦æ€è€ƒ (å•Ÿå‹•ç¹ªåœ–å¼•æ“)..."
                
                with st.spinner(loading_text):
                    try:
                        # Prompt æŒ‡ä»¤é›†
                        guardrail = "ã€æœ€é«˜é˜²è­·ã€‘éèª²æ¥­ç›¸é—œ(è‡ªæ‹/é¢¨æ™¯)è«‹å›å‚³: REFUSE_OFF_TOPIC"
                        transcription = f"ã€éš±è—ä»»å‹™ã€‘å°‡é¡Œç›® '{question_target}' è½‰è­¯ç‚ºæ–‡å­—ï¼Œä¸¦å°‡å¹¾ä½•ç‰¹å¾µè½‰ç‚ºæ–‡å­—æè¿°ï¼ŒåŒ…åœ¨ `===DESC===` èˆ‡ `===DESC_END===` ä¹‹é–“ã€‚"
                        formatting = "ã€æ’ç‰ˆã€‘æ–‡å­—ç®—å¼åˆ†è¡Œã€‚é•·ç®—å¼ç”¨ `\\\\` æ›è¡Œã€‚"
                        
                        plotting = """
                        ã€ç¹ªåœ–èƒ½åŠ›å•Ÿå‹•ã€‘
                        å¦‚æœé¡Œç›®æ¶‰åŠã€Œå‡½æ•¸åœ–å½¢ã€æˆ–ã€Œå¹¾ä½•åº§æ¨™ã€ï¼Œè«‹ç”¢ç”Ÿ Python ç¨‹å¼ç¢¼ (matplotlib + numpy)ã€‚
                        1. ç¨‹å¼ç¢¼å¿…é ˆèƒ½ç›´æ¥åŸ·è¡Œã€‚
                        2. å¿…é ˆåŒ…åœ¨ `===PLOT===` èˆ‡ `===PLOT_END===` ä¹‹é–“ã€‚
                        3. åœ–è¡¨è«‹ç›¡é‡ç¾è§€ï¼Œæ¨™è¨»åº§æ¨™è»¸ã€‚
                        """

                        common_role = f"è§’è‰²ï¼šä½ æ˜¯ Jutorã€‚å¹´ç´šï¼š{selected_grade}ã€‚é¡Œç›®ï¼š{question_target}ã€‚"
                        if mode == "verbal":
                            style = "é¢¨æ ¼ï¼šå¹½é»˜å£èªã€è­¬å–»æ•™å­¸ã€æ­¥é©ŸåŒ–ã€‚"
                        else:
                            style = "é¢¨æ ¼ï¼šç´”ç®—å¼ã€LaTeXã€æ¥µç°¡ã€‚"

                        prompt = f"""
                        {guardrail}
                        {transcription}
                        {formatting}
                        {plotting}
                        
                        {common_role}
                        {style}

                        çµæ§‹è¦æ±‚ï¼š
                        (æè¿°) ===DESC=== ... ===DESC_END===
                        (ç¹ªåœ–-é¸ç”¨) ===PLOT=== python code ===PLOT_END===
                        (è§£é¡Œ)
                        ç¢ºèªé¡Œç›® ===STEP===
                        è§£é¡Œéç¨‹(æ¯ä¸€æ­¥STEPåˆ†éš”) ===STEP===
                        ...
                        æœ¬é¡Œç­”æ¡ˆ ===STEP=== ã€é©—æ”¶é¡é¡Œã€‘ ===STEP=== ã€é¡é¡Œè©³è§£ã€‘
                        """

                        response = call_gemini_with_rotation(prompt, image)
                        
                        if "REFUSE_OFF_TOPIC" in response.text:
                            st.error("ğŸ™…â€â™‚ï¸ é€™å€‹å­¸æ ¡å¥½åƒä¸æœƒè€ƒå–”ï¼")
                        else:
                            full_text = response.text
                            
                            # 1. æå–æè¿°
                            image_desc = "ç„¡æè¿°"
                            desc_match = re.search(r"===DESC===(.*?)===DESC_END===", full_text, re.DOTALL)
                            if desc_match:
                                image_desc = desc_match.group(1).strip()
                                full_text = full_text.replace(desc_match.group(0), "")

                            # 2. æå–ç¹ªåœ–ä»£ç¢¼
                            plot_code = None
                            plot_match = re.search(r"===PLOT===(.*?)===PLOT_END===", full_text, re.DOTALL)
                            if plot_match:
                                plot_code = plot_match.group(1).strip()
                                plot_code = plot_code.replace("```python", "").replace("```", "")
                                full_text = full_text.replace(plot_match.group(0), "")
                            
                            st.session_state.plot_code = plot_code
                            
                            # 3. è™•ç†æ­¥é©Ÿ
                            raw_steps = full_text.split("===STEP===")
                            st.session_state.solution_steps = [step.strip() for step in raw_steps if step.strip()]
                            st.session_state.step_index = 0
                            st.session_state.is_solving = True
                            st.session_state.streaming_done = False
                            st.session_state.in_qa_mode = False
                            st.session_state.qa_history = []
                            st.session_state.data_saved = False

                            save_to_google_sheets(selected_grade, mode, image_desc, full_text)
                            st.rerun()

                    except Exception as e:
                        if "429" in str(e) or "Quota" in str(e): 
                            st.warning("ğŸ¥µ ç³»çµ±å¿™ç¢Œä¸­ (High Traffic)...")
                            st.error("è«‹ç¨å€™é‡è©¦ï¼")
                        else: st.error(f"éŒ¯èª¤ï¼š{e}")

# ================= è§£é¡Œäº’å‹• =================

if st.session_state.is_solving and st.session_state.solution_steps:
    
    header_text = "ğŸ—£ï¸ Jutor å£èªæ•™å­¸ä¸­" if st.session_state.solve_mode == "verbal" else "ğŸ”¢ ç´”ç®—å¼æ¨å°ä¸­"
    st.subheader(header_text)
    
    # é¡¯ç¤ºç¹ªåœ–
    if st.session_state.plot_code:
        with st.expander("ğŸ“Š æŸ¥çœ‹å¹¾ä½•/å‡½æ•¸åœ–å½¢ (AI ç¹ªè£½)", expanded=True):
            execute_and_show_plot(st.session_state.plot_code)

    # é¡¯ç¤ºæ­¥é©Ÿ
    for i in range(st.session_state.step_index):
        with st.chat_message("assistant", avatar="é³©"):
            st.markdown(st.session_state.solution_steps[i])
            
    current_step_text = st.session_state.solution_steps[st.session_state.step_index]
    with st.chat_message("assistant", avatar="é³©"):
        if not st.session_state.streaming_done:
            trigger_vibration()
            st.write_stream(stream_text(current_step_text))
            st.session_state.streaming_done = True
        else:
            st.markdown(current_step_text)

    # æŒ‰éˆ•æ§åˆ¶
    total_steps = len(st.session_state.solution_steps)
    if st.session_state.step_index < total_steps - 1:
        if not st.session_state.in_qa_mode:
            st.markdown("---")
            col_back, col_ask, col_next = st.columns([1, 1, 2])
            
            with col_back:
                def prev_step():
                    if st.session_state.step_index > 0:
                        st.session_state.step_index -= 1
                        st.session_state.streaming_done = True 
                st.button("â¬…ï¸ ä¸Šä¸€æ­¥", on_click=prev_step, disabled=(st.session_state.step_index == 0), use_container_width=True)

            with col_ask:
                def enter_qa_mode():
                    st.session_state.in_qa_mode = True
                    context_prompt = f"è¬›è§£æ­¥é©Ÿï¼š{current_step_text}ã€‚"
                    if st.session_state.solve_mode == "math": context_prompt += "ç›®å‰æ˜¯ç´”ç®—å¼æ¨¡å¼ï¼Œå­¸ç”Ÿä¸æ‡‚ã€‚"
                    st.session_state.qa_history = [{"role": "user", "parts": [context_prompt]}, {"role": "model", "parts": ["è«‹æå•ã€‚"]}]
                st.button("ğŸ¤” æˆ‘æƒ³å•...", on_click=enter_qa_mode, use_container_width=True)

            with col_next:
                btn_label = "âœ… æˆ‘æ‡‚äº†ï¼Œä¸‹ä¸€æ­¥ï¼"
                if st.session_state.step_index == total_steps - 2: btn_label = "ğŸ‘€ æ ¸å°é¡é¡Œç­”æ¡ˆ"
                def next_step():
                    st.session_state.step_index += 1
                    st.session_state.streaming_done = False
                st.button(btn_label, on_click=next_step, use_container_width=True, type="primary")

        else:
            with st.container(border=True):
                st.markdown("#### ğŸ’¡ æå•æ™‚é–“")
                for msg in st.session_state.qa_history[2:]:
                     with st.chat_message("user" if msg["role"] == "user" else "assistant", avatar="ğŸ‘¤" if msg["role"] == "user" else "é³©"):
                         st.markdown(msg["parts"][0])
                user_question = st.chat_input("è«‹è¼¸å…¥å•é¡Œ...")
                if user_question:
                    with st.chat_message("user", avatar="ğŸ‘¤"): st.markdown(user_question)
                    st.session_state.qa_history.append({"role": "user", "parts": [user_question]})
                    with st.chat_message("assistant", avatar="é³©"):
                        with st.spinner("æ€è€ƒä¸­..."):
                            try:
                                full_prompt = "å°è©±ç´€éŒ„:\n" + "\n".join([f"{h['role']}:{h['parts'][0]}" for h in st.session_state.qa_history]) + f"\næ–°å•é¡Œ:{user_question}"
                                response = call_gemini_with_rotation(full_prompt)
                                st.write_stream(stream_text(response.text))
                                st.session_state.qa_history.append({"role": "model", "parts": [response.text]})
                            except: st.error("å¿™ç¢Œä¸­")
                    st.rerun()
                def exit_qa_mode():
                    st.session_state.in_qa_mode = False
                    st.session_state.qa_history = []
                st.button("ğŸ‘Œ å›åˆ°ä¸»æµç¨‹", on_click=exit_qa_mode, use_container_width=True)

    else:
        st.markdown("---")
        st.success("ğŸ‰ æ­å–œå®Œæˆï¼")
        col_end_back, col_end_reset = st.columns([1, 2])
        with col_end_back:
            def prev_step_end():
                st.session_state.step_index -= 1
                st.session_state.streaming_done = True
            st.button("â¬…ï¸ ä¸Šä¸€æ­¥", on_click=prev_step_end, use_container_width=True)
        with col_end_reset:
            if st.button("ğŸ”„ é‡æ–°å•åˆ¥é¡Œ", use_container_width=True):
                st.session_state.is_solving = False
                st.session_state.solution_steps = []
                st.session_state.step_index = 0
                st.session_state.streaming_done = False
                st.session_state.in_qa_mode = False
                st.session_state.data_saved = False
                st.session_state.plot_code = None
                st.rerun()
