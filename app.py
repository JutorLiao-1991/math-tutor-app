import streamlit as st
import google.generativeai as genai
from PIL import Image
import os
import time
import streamlit.components.v1 as components
import pandas as pd
from datetime import datetime
import random
import re # ç”¨ä¾†æŠ“å–éŒ¯èª¤è¨Šæ¯ä¸­çš„ç­‰å¾…ç§’æ•¸

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="é³©ç‰¹æ•¸ç†ï¼¡ï¼©å°å¹«æ‰‹", page_icon="ğŸ¦”", layout="centered")

# --- åˆå§‹åŒ– Session State ---
if 'step_index' not in st.session_state:
    st.session_state.step_index = 0
if 'solution_steps' not in st.session_state:
    st.session_state.solution_steps = []
if 'is_solving' not in st.session_state:
    st.session_state.is_solving = False
if 'streaming_done' not in st.session_state:
    st.session_state.streaming_done = False
if 'in_qa_mode' not in st.session_state:
    st.session_state.in_qa_mode = False
if 'qa_history' not in st.session_state:
    st.session_state.qa_history = []
if 'solve_mode' not in st.session_state:
    st.session_state.solve_mode = "verbal"
if 'data_saved' not in st.session_state:
    st.session_state.data_saved = False
if 'daily_records' not in st.session_state:
    st.session_state.daily_records = []

# --- å‡½æ•¸ï¼šæ‰“å­—æ©Ÿæ•ˆæœ ---
def stream_text(text):
    for char in text:
        yield char
        time.sleep(0.02)

# --- å‡½æ•¸ï¼šè§¸ç™¼éœ‡å‹• ---
def trigger_vibration():
    vibrate_js = """<script>if(navigator.vibrate){navigator.vibrate(30);}</script>"""
    components.html(vibrate_js, height=0, width=0)

# --- æ ¸å¿ƒå‡½æ•¸ï¼šå¼·å¤§çš„ API å‘¼å«å™¨ (å«è‡ªå‹•æ›é‘°åŒ™åŠŸèƒ½) ---
def call_gemini_with_rotation(prompt_content, image_input=None):
    # 1. å–å¾—æ‰€æœ‰é‘°åŒ™
    try:
        keys = st.secrets["API_KEYS"]
        if isinstance(keys, str): # ç›¸å®¹èˆŠè¨­å®š (å¦‚æœåªå¡«äº†ä¸€è¡Œå­—ä¸²)
            keys = [keys]
    except:
        st.error("ç³»çµ±éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° API_KEYS è¨­å®šï¼Œè«‹æª¢æŸ¥ Secretsã€‚")
        st.stop()

    # 2. éš¨æ©Ÿæ‰“äº‚é‘°åŒ™é †åº (è² è¼‰å¹³è¡¡)
    # é€™æ¨£å¤§å®¶ä¸æœƒéƒ½æ“ åœ¨ç¬¬ä¸€æŠŠé‘°åŒ™
    shuffled_keys = keys.copy()
    random.shuffle(shuffled_keys)
    
    last_error = None
    
    # 3. å˜—è©¦è¿´åœˆ
    for key in shuffled_keys:
        try:
            # è¨­å®šç›®å‰çš„é‘°åŒ™
            genai.configure(api_key=key)
            model = genai.GenerativeModel('models/gemini-2.5-flash')
            
            # ç™¼é€è«‹æ±‚ (åˆ¤æ–·æœ‰æ²’æœ‰åœ–ç‰‡)
            if image_input:
                response = model.generate_content([prompt_content, image_input])
            else:
                # é€™æ˜¯çµ¦å•ç­”æ¨¡å¼ç”¨çš„ (ç´”æ–‡å­— history)
                # æ³¨æ„ï¼šGemini çš„ chat session éœ€è¦ç‰¹æ®Šçš„æ›é‘°åŒ™è™•ç†ï¼Œé€™è£¡ç°¡åŒ–ç‚ºç›´æ¥èª¿ç”¨
                # å¦‚æœæ˜¯å¤šè¼ªå°è©±ï¼Œæ› Key å¯èƒ½æœƒå°è‡´ä¸Šä¸‹æ–‡éºå¤±ï¼Œ
                # ä½†ç‚ºäº†æ•‘æ€¥ 429 éŒ¯èª¤ï¼Œæˆ‘å€‘é€™é‚Šæ¡ç”¨å–®æ¬¡ç”Ÿæˆæˆ–éœ€é‡å»º history
                # é€™è£¡ç‚ºäº†ç°¡åŒ–ï¼Œè‹¥æ˜¯ QA æ¨¡å¼å»ºè­°ä½¿ç”¨ generate_content å¸¶å…¥å®Œæ•´ history text
                response = model.generate_content(prompt_content)
                
            return response # æˆåŠŸå°±ç›´æ¥å›å‚³ï¼ŒçµæŸè¿´åœˆ

        except Exception as e:
            error_str = str(e)
            # å¦‚æœæ˜¯ 429 (Quota Exceeded) æˆ– 503 (Server Busy)ï¼Œå°±æ›ä¸‹ä¸€æŠŠé‘°åŒ™
            if "429" in error_str or "Quota exceeded" in error_str or "503" in error_str:
                print(f"Key ...{key[-4:]} é¡åº¦å·²æ»¿ï¼Œåˆ‡æ›ä¸‹ä¸€æŠŠ...") # å¾Œå°ç´€éŒ„
                last_error = e
                continue # ç¹¼çºŒè¿´åœˆï¼Œè©¦ä¸‹ä¸€æŠŠ
            else:
                # å¦‚æœæ˜¯å…¶ä»–åš´é‡éŒ¯èª¤ (å¦‚ 400 åƒæ•¸éŒ¯èª¤)ï¼Œç›´æ¥å ±éŒ¯ï¼Œä¸ç”¨æ›é‘°åŒ™è©¦äº†
                raise e
    
    # 4. å¦‚æœæ‰€æœ‰é‘°åŒ™éƒ½è©¦éäº†é‚„æ˜¯å¤±æ•—
    raise last_error

# ================= ä»‹é¢è¨­è¨ˆ =================

col1, col2 = st.columns([1, 4]) 
with col1:
    if os.path.exists("logo.jpg"):
        st.image("logo.jpg", use_column_width=True)
    else:
        st.write("ğŸ¦”") 
with col2:
    st.title("é³©ç‰¹æ•¸ç†ï¼¡ï¼©å°å¹«æ‰‹")

# --- è€å¸«å¾Œå° ---
with st.expander("ğŸ‘¨â€ğŸ« è€å¸«å¾Œå° (ä¸‹è¼‰ä»Šæ—¥ç´€éŒ„)"):
    st.write(f"ç›®å‰å·²ç´¯ç© **{len(st.session_state.daily_records)}** ç­†ç´€éŒ„")
    if len(st.session_state.daily_records) > 0:
        df = pd.DataFrame(st.session_state.daily_records)
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ CSV",
            data=csv,
            file_name=f"jutor_history_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
        )

# --- å¹´ç´š ---
st.markdown("---")
col_grade_label, col_grade_select = st.columns([2, 3])
with col_grade_label:
    st.markdown("### ğŸ“‹ è«‹å…ˆé¸æ“‡å¹´ç´šï¼š")
    st.caption("Jutor æœƒä¾æ­¤èª¿æ•´é›£åº¦ã€‚")
with col_grade_select:
    selected_grade = st.selectbox(
        "å¹´ç´šé¸å–®",
        ("åœ‹ä¸€", "åœ‹äºŒ", "åœ‹ä¸‰", "é«˜ä¸€", "é«˜äºŒ", "é«˜ä¸‰"),
        label_visibility="collapsed"
    )
st.markdown("---")

# --- ä¸Šå‚³å€ ---
if not st.session_state.is_solving:
    st.subheader("ğŸ“¸ 1ï¸âƒ£ ä¸Šå‚³é¡Œç›® & æŒ‡å®š")
    uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡ (JPG, PNG)", type=["jpg", "png", "jpeg"], label_visibility="collapsed")

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='é¡Œç›®é è¦½', use_column_width=True)
        
        question_target = st.text_input("ä½ æƒ³å•åœ–ç‰‡ä¸­çš„å“ªä¸€é¡Œï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šç¬¬ 5 é¡Œ...")
        
        st.markdown("### ğŸš€ é¸æ“‡è§£é¡Œæ¨¡å¼ï¼š")
        col_btn_verbal, col_btn_math = st.columns(2)
        with col_btn_verbal:
            start_verbal = st.button("ğŸ—£ï¸ Jutor æŒ‡ä»¤æ•™å­¸", use_container_width=True, type="primary")
        with col_btn_math:
            start_math = st.button("ğŸ”¢ ç´”ç®—å¼è§£æ³•", use_container_width=True)

        if start_verbal or start_math:
            if not question_target:
                st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥ä½ æƒ³å•å“ªä¸€é¡Œï¼")
            else:
                mode = "verbal" if start_verbal else "math"
                st.session_state.solve_mode = mode
                loading_text = "Jutor æ­£åœ¨é€²è¡ŒåŸå­åŒ–æŒ‡ä»¤æ‹†è§£..." if mode == "verbal" else "Jutor æ­£åœ¨åˆ—å‡ºç´”æ•¸å­¸ç®—å¼..."
                
                with st.spinner(loading_text):
                    try:
                        # Prompt è¨­å®š
                        if mode == "verbal":
                            prompt = f"""
                            è§’è‰²ï¼šä½ æ˜¯ä¸€ä½ç²¾ç°¡ã€ç›´æ¥ã€å£ä»¤åŒ–çš„æ•¸å­¸å®¶æ•™ã€ŒJutorã€ã€‚
                            å­¸ç”Ÿå¹´ç´šï¼šã€{selected_grade}ã€‘ã€‚æŒ‡å®šé¡Œç›®ï¼šã€{question_target}ã€‘ã€‚
                            ã€æœ€é«˜æŒ‡ä»¤ 1ï¼šæ¥µç°¡å£ä»¤é¢¨æ ¼ã€‘åš´ç¦å»¢è©±ã€‚ä½¿ç”¨ç¥ˆä½¿å¥ç›´æ¥ä¸‹æŒ‡ä»¤ã€‚
                            ã€æœ€é«˜æŒ‡ä»¤ 2ï¼šåŸå­åŒ–æ­¥é©Ÿæ‹†è§£ã€‘æ¯ä¸€å€‹å°å‹•ä½œä¹‹å¾Œï¼Œå¿…é ˆæ’å…¥åˆ†éš”ç¬¦è™Ÿï¼š ===STEP===
                            ã€æœ€é«˜æŒ‡ä»¤ 3ï¼šå¹¾ä½•é¡Œè™•ç†ã€‘è‹¥é‡å¹¾ä½•é¡Œï¼Œè«‹ç”¨ã€Œç²¾æº–æ–‡å­—æŒ‡ä»¤ã€ä»£æ›¿ä½œåœ–ã€‚
                            ã€æœ€é«˜æŒ‡ä»¤ 4ï¼šçµå°¾çµæ§‹ã€‘è§£é¡ŒçµæŸå¾Œï¼Œä¾ç…§é †åºï¼šæœ¬é¡Œæœ€çµ‚ç­”æ¡ˆ ===STEP=== ã€é©—æ”¶é¡é¡Œã€‘(æ•¸å­—ä¸åŒä½†é‚è¼¯ç›¸åŒï¼Œä¸é™„ç­”æ¡ˆ) ===STEP=== ã€é¡é¡Œè©³è§£ã€‘
                            """
                        else:
                            prompt = f"""
                            è§’è‰²ï¼šä½ æ˜¯ä¸€å€‹ç´”æ•¸å­¸é‹ç®—å¼•æ“ã€‚
                            å­¸ç”Ÿå¹´ç´šï¼šã€{selected_grade}ã€‘ã€‚æŒ‡å®šé¡Œç›®ï¼šã€{question_target}ã€‘ã€‚
                            ã€æœ€é«˜æŒ‡ä»¤ 1ï¼šç´”ç®—å¼æ¨¡å¼ã€‘åš´ç¦å†—é•·ä¸­æ–‡ã€‚ä»¥ LaTeX ç‚ºä¸»ã€‚
                            ã€æœ€é«˜æŒ‡ä»¤ 2ï¼šåŸå­åŒ–æ­¥é©Ÿæ‹†è§£ã€‘æ¯ä¸€å€‹ç®—å¼è®Šæ›å¾Œï¼Œå¿…é ˆæ’å…¥åˆ†éš”ç¬¦è™Ÿï¼š ===STEP===
                            ã€æœ€é«˜æŒ‡ä»¤ 3ï¼šçµå°¾çµæ§‹ã€‘è§£é¡ŒçµæŸå¾Œï¼Œä¾ç…§é †åºï¼šæœ¬é¡Œæœ€çµ‚ç­”æ¡ˆ ===STEP=== ã€é©—æ”¶é¡é¡Œã€‘(åƒ…é¡Œç›®) ===STEP=== ã€é¡é¡Œè§£ç­”ã€‘
                            """

                        # --- æ”¹æˆå‘¼å«æˆ‘å€‘çš„ã€Œè‡ªå‹•æ›é‘°åŒ™ã€å‡½æ•¸ ---
                        response = call_gemini_with_rotation(prompt, image)
                        
                        raw_steps = response.text.split("===STEP===")
                        st.session_state.solution_steps = [step.strip() for step in raw_steps if step.strip()]
                        st.session_state.step_index = 0
                        st.session_state.is_solving = True
                        st.session_state.streaming_done = False
                        st.session_state.in_qa_mode = False
                        st.session_state.qa_history = []
                        st.session_state.data_saved = False

                        # ç´€éŒ„
                        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        mode_str = "æŒ‡ä»¤æ•™å­¸" if mode == "verbal" else "ç´”ç®—å¼"
                        new_record = {
                            "æ™‚é–“": timestamp,
                            "å¹´ç´š": selected_grade,
                            "æ¨¡å¼": mode_str,
                            "é¡Œç›®æè¿°": question_target,
                            "AIå®Œæ•´è©³è§£": response.text
                        }
                        st.session_state.daily_records.append(new_record)
                        
                        st.rerun()

                    except Exception as e:
                        # --- ã€é—œéµä¿®æ”¹ã€‘å‹å–„çš„éŒ¯èª¤æ””æˆª ---
                        error_msg = str(e)
                        if "429" in error_msg or "Quota exceeded" in error_msg:
                            # å˜—è©¦æŠ“å–ç­‰å¾…æ™‚é–“
                            wait_time = "60" # é è¨­ä¸€åˆ†é˜
                            match = re.search(r"retry in (\d+(\.\d+)?)", error_msg)
                            if match:
                                wait_time = str(int(float(match.group(1))) + 5) # ç„¡æ¢ä»¶é€²ä½ä¸¦å¤šåŠ 5ç§’ç·©è¡
                            
                            st.warning(f"ğŸ¢ Jutor è€å¸«ç›®å‰è™•ç†å¤ªå¤šå­¸ç”Ÿçš„å•é¡Œï¼Œæ­£åœ¨å–å£æ°´ä¼‘æ¯...")
                            st.error(f"âš ï¸ ç³»çµ±éè¼‰ä¿è­·ä¸­ï¼Œè«‹ç¨å€™ {wait_time} ç§’å¾Œå†è©¦ä¸€æ¬¡ï¼")
                        else:
                            st.error(f"é€£ç·šç™¼ç”Ÿéé æœŸéŒ¯èª¤ï¼š{e}")

# ================= è§£é¡Œäº’å‹• (éƒ¨åˆ†å¾®èª¿ä»¥æ”¯æ´ QA çš„æ›é‘°åŒ™) =================

if st.session_state.is_solving and st.session_state.solution_steps:
    
    header_text = "ğŸ“ Jutor å£ä»¤æ•™å­¸ä¸­" if st.session_state.solve_mode == "verbal" else "ğŸ”¢ ç´”ç®—å¼æ¨å°ä¸­"
    st.subheader(header_text)
    
    for i in range(st.session_state.step_index):
        with st.chat_message("assistant", avatar="ğŸ¦”"):
            st.markdown(st.session_state.solution_steps[i])
            
    current_step_text = st.session_state.solution_steps[st.session_state.step_index]
    with st.chat_message("assistant", avatar="ğŸ¦”"):
        if not st.session_state.streaming_done:
            trigger_vibration()
            st.write_stream(stream_text(current_step_text))
            st.session_state.streaming_done = True
        else:
            st.markdown(current_step_text)

    total_steps = len(st.session_state.solution_steps)
    if st.session_state.step_index < total_steps - 1:
        if not st.session_state.in_qa_mode:
            st.markdown("---")
            col_next, col_ask = st.columns([3, 2])
            
            btn_label = "âœ… æˆ‘æ‡‚äº†ï¼Œä¸‹ä¸€æ­¥ï¼"
            if st.session_state.step_index == total_steps - 2:
                btn_label = "ğŸ‘€ æ ¸å°é¡é¡Œç­”æ¡ˆ"
            
            with col_next:
                def next_step():
                    st.session_state.step_index += 1
                    st.session_state.streaming_done = False
                st.button(btn_label, on_click=next_step, use_container_width=True, type="primary")
            
            with col_ask:
                def enter_qa_mode():
                    st.session_state.in_qa_mode = True
                    context_prompt = f"ä½ æ­£åœ¨è¬›è§£é€™å€‹æ­¥é©Ÿï¼š{current_step_text}ã€‚"
                    if st.session_state.solve_mode == "math":
                        context_prompt += "ç›®å‰æ˜¯ã€ç´”ç®—å¼æ¨¡å¼ã€‘ï¼Œä½†å­¸ç”Ÿçœ‹ä¸æ‡‚é€™ä¸€æ­¥ï¼Œè«‹è§£é‡‹ã€‚"
                    st.session_state.qa_history = [
                        {"role": "user", "parts": [context_prompt]}, # ä¿®æ­£ï¼šå°‡èƒŒæ™¯è¨­å®šå½è£æˆç¬¬ä¸€å‰‡ user prompt
                        {"role": "model", "parts": ["äº†è§£ï¼Œè«‹èªªå‡ºä½ çš„å•é¡Œã€‚"]} # å‡è£ AI å·²ç¶“æ”¶åˆ°
                    ]
                st.button("ğŸ¤” ä¸å¤ªæ‡‚ï¼Œæˆ‘æƒ³å•...", on_click=enter_qa_mode, use_container_width=True)

        else:
            with st.container(border=True):
                st.markdown("#### ğŸ’¡ æå•æ™‚é–“")
                # é¡¯ç¤ºæ­·å²å°è©± (è·³éå‰å…©å‰‡èƒŒæ™¯è¨­å®š)
                for msg in st.session_state.qa_history[2:]:
                     with st.chat_message("user" if msg["role"] == "user" else "assistant", avatar="ğŸ‘¤" if msg["role"] == "user" else "ğŸ¦”"):
                         st.markdown(msg["parts"][0])

                user_question = st.chat_input("è«‹è¼¸å…¥å•é¡Œ...")
                if user_question:
                    with st.chat_message("user", avatar="ğŸ‘¤"):
                        st.markdown(user_question)
                    st.session_state.qa_history.append({"role": "user", "parts": [user_question]})
                    
                    with st.chat_message("assistant", avatar="ğŸ¦”"):
                        with st.spinner("æ€è€ƒä¸­..."):
                            try:
                                # é€™è£¡æˆ‘å€‘éœ€è¦æŠŠæ•´å€‹ history è½‰æˆæ–‡å­—ä¸²ï¼Œè®“æ›é‘°åŒ™å‡½æ•¸å¯ä»¥åƒ
                                # é€™æ˜¯ç‚ºäº†é¿å…æ› Key å¾Œ session å¤±æ•ˆçš„æ¬Šå®œä¹‹è¨ˆ
                                full_prompt_text = "ä»¥ä¸‹æ˜¯å°è©±æ­·å²ï¼š\n"
                                for h in st.session_state.qa_history:
                                    role = "å­¸ç”Ÿ" if h["role"] == "user" else "Jutor"
                                    full_prompt_text += f"{role}: {h['parts'][0]}\n"
                                full_prompt_text += f"å­¸ç”Ÿæœ€æ–°å•é¡Œ: {user_question}\nè«‹å›ç­”å­¸ç”Ÿçš„å•é¡Œã€‚"
                                
                                # ä½¿ç”¨è‡ªå‹•æ›é‘°åŒ™å‡½æ•¸
                                response = call_gemini_with_rotation(full_prompt_text)
                                
                                st.write_stream(stream_text(response.text))
                                st.session_state.qa_history.append({"role": "model", "parts": [response.text]})
                            except Exception as e:
                                st.error(f"é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹é‡è©¦ã€‚")

                    st.rerun()

                def exit_qa_mode():
                    st.session_state.in_qa_mode = False
                    st.session_state.qa_history = []
                st.button("ğŸ‘Œ å›åˆ°ä¸»æµç¨‹", on_click=exit_qa_mode, use_container_width=True)

    else:
        st.markdown("---")
        st.success("ğŸ‰ æ­å–œå®Œæˆæœ¬é¡Œå­¸ç¿’ï¼")
        if st.button("ğŸ”„ é‡æ–°å•åˆ¥é¡Œ", use_container_width=True):
            st.session_state.is_solving = False
            st.session_state.solution_steps = []
            st.session_state.step_index = 0
            st.session_state.streaming_done = False
            st.session_state.in_qa_mode = False
            st.rerun()
