import streamlit as st
import google.generativeai as genai
from PIL import Image
import os
import time
import streamlit.components.v1 as components
import random
import re
import gspread
import requests
from google.oauth2.service_account import Credentials
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np

# --- é é¢è¨­å®š (å¿…é ˆæ”¾ç¬¬ä¸€è¡Œ) ---
main_logo_path = "logo.jpg"
if os.path.exists(main_logo_path):
    page_icon_set = Image.open(main_logo_path)
else:
    page_icon_set = "ğŸ¦”"
assistant_avatar = "ğŸ¦”" 

st.set_page_config(page_title="é³©ç‰¹æ•¸ç†-AI Jutor", page_icon=page_icon_set, layout="centered")

# ==========================================
# ğŸ”“ ç™»å…¥æ©Ÿåˆ¶å·²ç§»é™¤ (v7.4/v7.6)
# ==========================================

# --- æ³¨å…¥è‡ªå®šç¾© CSS ---
def inject_custom_css():
    st.markdown(
        """
        <style>
        .katex-html { overflow-x: auto; overflow-y: hidden; max-width: 100%; display: block; padding-bottom: 5px; }
        .stMarkdown { max-width: 100%; overflow-wrap: break-word; }
        .stChatMessage .stChatMessageAvatar {
            width: 2.8rem;
            height: 2.8rem;
            background-color: #f0f2f6; 
            border-radius: 50%;
            object-fit: cover;
            font-size: 1.8rem;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        @media only screen and (max-width: 600px) {
            .stMarkdown p, .stMarkdown li, .stMarkdown div, .stChatMessage p {
                font-size: 15px !important;
                line-height: 1.6 !important;
            }
            h1 { font-size: 1.6rem !important; }
            h2 { font-size: 1.4rem !important; }
            h3 { font-size: 1.2rem !important; }
            .katex { font-size: 1.1em !important; }
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

# --- å¿«å–å­—é«”è¨­å®š ---
@st.cache_resource
def configure_chinese_font():
    font_file = "NotoSansTC-Regular.ttf"
    if os.path.exists(font_file):
        try:
            fm.fontManager.addfont(font_file)
            prop = fm.FontProperties(fname=font_file)
            font_name = prop.get_name()
            plt.rcParams['font.family'] = font_name
            plt.rcParams['axes.unicode_minus'] = False 
            return font_name
        except Exception as e:
            return "sans-serif"
    else:
        return "sans-serif"

# --- å¿«å– Google Sheets é€£ç·š ---
@st.cache_resource
def get_google_sheet_client():
    try:
        if "gcp_service_account" in st.secrets:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds_dict = dict(st.secrets["gcp_service_account"])
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
            creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(creds)
            return client
    except Exception as e:
        print(f"GCP é€£ç·šå¤±æ•—: {e}")
    return None

def save_to_google_sheets(grade, mode, image_desc, full_response, key_info=""):
    try:
        client = get_google_sheet_client()
        if client:
            sheet = client.open("Jutor_Learning_Data").sheet1
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            # ç¶­æŒå€’æ•˜æ’åˆ— (æ’å…¥åœ¨æ¨™é¡Œä¸‹æ–¹)
            sheet.insert_row([timestamp, grade, mode, image_desc, full_response, key_info], index=2)
            return True
    except Exception as e:
        st.cache_resource.clear()
        return False

# --- Telegram å›å ±å‡½å¼ ---
def send_telegram_alert(grade, question_desc, ai_response, student_comment):
    try:
        if "telegram" in st.secrets:
            token = st.secrets["telegram"]["bot_token"]
            chat_id = st.secrets["telegram"]["chat_id"]
            
            message = f"""
ğŸš¨ **Jutor éŒ¯èª¤å›å ±** ğŸš¨
-----------------------
ğŸ“… æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“ å¹´ç´š: {grade}
ğŸ—£ï¸ **å­¸ç”Ÿæ„è¦‹:** {student_comment}

ğŸ“ é¡Œç›®æè¿°: {question_desc[:100]}...
ğŸ¤– **AI çš„å›ç­”:**
{ai_response[:300]}... (å…§å®¹éé•·æˆªæ–·)
-----------------------
            """
            
            url = f"https://api.telegram.org/bot{token}/sendMessage"
            payload = {
                "chat_id": chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }
            requests.post(url, json=payload)
            return True
    except Exception as e:
        print(f"Telegram ç™¼é€å¤±æ•—: {e}")
        return False

# --- åˆå§‹åŒ– ---
inject_custom_css()
CORRECT_FONT_NAME = configure_chinese_font()

if 'step_index' not in st.session_state: st.session_state.step_index = 0
if 'solution_steps' not in st.session_state: st.session_state.solution_steps = []
if 'is_solving' not in st.session_state: st.session_state.is_solving = False
if 'streaming_done' not in st.session_state: st.session_state.streaming_done = False
if 'in_qa_mode' not in st.session_state: st.session_state.in_qa_mode = False
if 'qa_history' not in st.session_state: st.session_state.qa_history = []
if 'solve_mode' not in st.session_state: st.session_state.solve_mode = "verbal"
if 'data_saved' not in st.session_state: st.session_state.data_saved = False
if 'plot_code' not in st.session_state: st.session_state.plot_code = None
if 'use_pro_model' not in st.session_state: st.session_state.use_pro_model = False
if 'trigger_rescue' not in st.session_state: st.session_state.trigger_rescue = False
if 'used_key_suffix' not in st.session_state: st.session_state.used_key_suffix = "" 
if 'image_desc_cache' not in st.session_state: st.session_state.image_desc_cache = "" 
if 'full_text_cache' not in st.session_state: st.session_state.full_text_cache = ""   
if 'is_reporting' not in st.session_state: st.session_state.is_reporting = False

# --- å‡½æ•¸å€ ---
def trigger_vibration():
    vibrate_js = """<script>if(navigator.vibrate){navigator.vibrate(30);}</script>"""
    components.html(vibrate_js, height=0, width=0)

def execute_and_show_plot(code_snippet):
    try:
        plt.rcParams['font.family'] = CORRECT_FONT_NAME
        plt.rcParams['axes.unicode_minus'] = False
        plt.figure(figsize=(6, 4))
        plt.style.use('seaborn-v0_8-whitegrid') 
        local_scope = {'plt': plt, 'np': np}
        exec(code_snippet, globals(), local_scope)
        ax = plt.gca()
        if ax.get_title(): ax.set_title(ax.get_title(), fontname=CORRECT_FONT_NAME)
        if ax.get_xlabel(): ax.set_xlabel(ax.get_xlabel(), fontname=CORRECT_FONT_NAME)
        if ax.get_ylabel(): ax.set_ylabel(ax.get_ylabel(), fontname=CORRECT_FONT_NAME)
        legend = ax.get_legend()
        if legend:
            plt.setp(legend.get_texts(), fontname=CORRECT_FONT_NAME)
        st.pyplot(plt)
        plt.close()
    except Exception as e:
        st.warning(f"åœ–å½¢ç¹ªè£½å¤±æ•—: {e}")

# --- ã€æ’ç‰ˆä¿®å¾© v7.6ï¼šæ–°å¢ç¶ è‰²ä»£ç¢¼è½‰LaTeXåŠŸèƒ½ã€‘ ---
def clean_output_format(text):
    if not text: return text
    
    # 0. æ¸…é™¤é›œè³ª
    text = text.strip().lstrip("'").lstrip('"').rstrip("'").rstrip('"')
    
    # 1. ã€æ–°å¢ã€‘å°‡ Markdown Inline Code (`x=1`) å¼·åˆ¶è½‰ç‚º LaTeX ($x=1$)
    # é€™è¡Œæ­£å‰‡è¡¨é”å¼æœƒæŠ“å–è¢«å–®å¼•è™ŸåŒ…ä½çš„å…§å®¹ï¼Œåªè¦ä¸æ˜¯å¤šè¡Œç¨‹å¼ç¢¼(```)ï¼Œå°±æŠŠå®ƒè®Šæˆæ•¸å­¸å…¬å¼
    text = re.sub(r'(?<!`)`([^`\n]+)`(?!`)', r'$\1$', text)

    # 2. Block Math è½‰ Inline Math
    def block_to_inline(match):
        content = match.group(1)
        if len(content) < 50 and '\\\\' not in content and 'align' not in content:
            return f"${content.strip()}$"
        return match.group(0)
    text = re.sub(r'\$\$([\s\S]*?)\$\$', block_to_inline, text)
    
    # 3. æ‹¬è™Ÿèˆ‡æ¨™é»ä¿®å¾©
    text = re.sub(r'([\(ï¼ˆ])\s*\n\s*(.*?)\s*\n\s*([\)ï¼‰])', r'\1\2\3', text)
    text = re.sub(r'\n\s*([ï¼Œã€‚ã€ï¼ï¼Ÿï¼š,.?])', r'\1', text)
    
    # 4. ä¸­æ–‡é»åˆåŠ‘
    cjk = r'[\u4e00-\u9fa5]'
    short_content = r'(?:(?!\n|â€¢|- |\* ).){1,30}' 
    for _ in range(2):
        pattern = f'(?<={cjk})\s*\\n+\s*({short_content})\s*\\n+\s*(?={cjk}|[ï¼Œã€‚ï¼ï¼Ÿï¼š,.?])'
        text = re.sub(pattern, r' \1 ', text)
    
    return text

def call_gemini_with_rotation(prompt_content, image_input=None, use_pro=False):
    try:
        keys = st.secrets["API_KEYS"]
        if isinstance(keys, str): keys = [keys]
    except:
        st.error("API_KEYS è¨­å®šéŒ¯èª¤")
        st.stop()
    
    target_keys = keys.copy() 
    if use_pro:
        model_name = 'models/gemini-2.5-pro'
    else:
        model_name = 'models/gemini-2.5-flash'
    last_error = None
    for key in target_keys:
        try:
            genai.configure(api_key=key)
            model = genai.GenerativeModel(model_name)
            if image_input:
                response = model.generate_content([prompt_content, image_input])
            else:
                response = model.generate_content(prompt_content)
            return response, key[-4:] 
        except Exception as e:
            if "429" in str(e) or "Quota" in str(e) or "503" in str(e):
                last_error = e
                continue
            else:
                raise e
    raise last_error

col1, col2 = st.columns([1, 4]) 
with col1:
    if os.path.exists(main_logo_path):
        st.image(main_logo_path, use_column_width=True)
    else:
        st.markdown("<div style='font-size: 3rem; text-align: center;'>ğŸ¦”</div>", unsafe_allow_html=True)

with col2:
    st.title("é³©ç‰¹æ•¸ç†-AI Jutor")
    st.caption("Jutor AI æ•™å­¸ç³»çµ± v7.6 (æ•¸å­¸æ’ç‰ˆä¿®å¾©ç‰ˆ 12/16)")

st.markdown("---")
col_grade_label, col_grade_select = st.columns([2, 3])
with col_grade_label:
    st.markdown("### ğŸ“‹ è«‹å…ˆé¸æ“‡å¹´ç´šï¼š")
    st.caption("Jutor æœƒä¾æ­¤èª¿æ•´è¬›è§£å£å»ã€‚")
with col_grade_select:
    selected_grade = st.selectbox("å¹´ç´š", ("å°äº”", "å°å…­", "åœ‹ä¸€", "åœ‹äºŒ", "åœ‹ä¸‰", "é«˜ä¸€", "é«˜äºŒ", "é«˜ä¸‰"), label_visibility="collapsed")
st.markdown("---")

if not st.session_state.is_solving:
    st.subheader("ğŸ“¸ 1ï¸âƒ£ ä¸Šå‚³é¡Œç›® & æŒ‡å®š")
    uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡ (JPG, PNG)", type=["jpg", "png", "jpeg"], label_visibility="collapsed")

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='é¡Œç›®é è¦½', use_column_width=True)
        question_target = st.text_input("ä½ æƒ³å•åœ–ç‰‡ä¸­çš„å“ªä¸€é¡Œï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šç¬¬ 5 é¡Œ...")
        
        st.markdown("### ğŸš€ é¸æ“‡è§£é¡Œæ¨¡å¼ï¼š")
        col_btn_verbal, col_btn_math = st.columns(2)
        with col_btn_verbal:
            start_verbal = st.button("ğŸ—£ï¸ Jutor å£èªæ•™å­¸", use_container_width=True, type="primary")
        with col_btn_math:
            start_math = st.button("ğŸ”¢ ç´”ç®—å¼è§£æ³•", use_container_width=True)

        if start_verbal or start_math or st.session_state.trigger_rescue:
            if not question_target:
                st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥ä½ æƒ³å•å“ªä¸€é¡Œï¼")
            else:
                if st.session_state.trigger_rescue:
                    mode = st.session_state.solve_mode
                    use_pro = True 
                    st.session_state.use_pro_model = True
                    st.session_state.trigger_rescue = False 
                else:
                    mode = "verbal" if start_verbal else "math"
                    st.session_state.solve_mode = mode
                    use_pro = False 
                    st.session_state.use_pro_model = False

                if use_pro:
                    loading_text = "Jutor Pro (2.5) æ­£åœ¨æ·±åº¦åˆ†æä¸¦ä¿®å¾©éŒ¯èª¤..."
                else:
                    loading_text = "Jutor AI (2.5) æ­£åœ¨æ€è€ƒæ€éº¼æ•™æœƒä½ é€™é¡Œ..."
                
                with st.spinner(loading_text):
                    try:
                        guardrail = "ã€éæ¿¾æ©Ÿåˆ¶ã€‘è«‹è¾¨è­˜åœ–ç‰‡å…§å®¹ã€‚è‹¥æ˜é¡¯ç‚ºã€Œè‡ªæ‹ç…§ã€é¢¨æ™¯ç…§ã€å¯µç‰©ç…§ã€ç­‰èˆ‡å­¸ç¿’ç„¡é—œçš„åœ–ç‰‡ï¼Œè«‹å›å‚³ REFUSE_OFF_TOPICã€‚è‹¥æ˜¯æ•¸å­¸é¡Œç›®ã€æ–‡å­—æˆªåœ–ã€åœ–è¡¨åˆ†æï¼Œå³ä½¿æ¨¡ç³Šæˆ–éå…¸å‹æ ¼å¼ï¼Œä¹Ÿè«‹å›ç­”ã€‚"
                        transcription = f"ã€éš±è—ä»»å‹™ã€‘å°‡é¡Œç›® '{question_target}' è½‰è­¯ç‚ºæ–‡å­—ï¼Œä¸¦å°‡å¹¾ä½•ç‰¹å¾µè½‰ç‚ºæ–‡å­—æè¿°ï¼ŒåŒ…åœ¨ `===DESC===` èˆ‡ `===DESC_END===` ä¹‹é–“ã€‚"
                        
                        formatting = """
                        ã€æ’ç‰ˆåš´æ ¼æŒ‡ä»¤ã€‘
                        1. **æ•¸å­¸å¼å¼·åˆ¶ LaTeX**ï¼šæ‰€æœ‰ç®—å¼ã€æ–¹ç¨‹å¼(å¦‚ x^2+1=0)ã€è®Šæ•¸(x, y)ã€æ•¸å­—é‹ç®—ï¼Œ**å‹™å¿…**ä½¿ç”¨ `$ ... $` åŒ…è£¹ (ä¾‹å¦‚ `$x^2+x-1=0$` æˆ– `$3 \\times 4 = 12$`)ã€‚
                        2. **ç¦æ­¢ Markdown Code**ï¼šåš´ç¦ä½¿ç”¨åå¼•è™Ÿ `...` ä¾†åŒ…è£¹æ•¸å­¸å¼ã€‚
                        3. **åˆ—è¡¨æ§åˆ¶**ï¼šé™¤éæ˜¯åˆ—èˆ‰ä¸åŒé¸é …ï¼Œå¦å‰‡ä¸è¦ä½¿ç”¨ Bullet Points ä¾†é¡¯ç¤ºå–®ä¸€æ•¸å€¼ã€‚
                        4. **ç›´å¼è¨ˆç®—**ï¼šåªæœ‰åœ¨é•·ç®—å¼æ¨å°æ™‚ï¼Œæ‰ä½¿ç”¨æ›è¡Œå°é½Šã€‚
                        """
                        
                        plotting = """
                        ã€ç¹ªåœ–èƒ½åŠ›å•Ÿå‹•ã€‘
                        1. åªæœ‰ç•¶é¡Œç›®æ˜ç¢ºæ¶‰åŠã€Œå‡½æ•¸åœ–å½¢ã€ã€ã€Œå¹¾ä½•åº§æ¨™ã€ã€ã€Œçµ±è¨ˆåœ–è¡¨ã€æ™‚ï¼Œæ‰ç”Ÿæˆ Python ç¨‹å¼ç¢¼ã€‚
                        2. ç¨‹å¼ç¢¼å¿…é ˆèƒ½ç›´æ¥åŸ·è¡Œï¼Œä¸¦åŒ…åœ¨ `===PLOT===` èˆ‡ `===PLOT_END===` ä¹‹é–“ã€‚
                        3. åœ–è¡¨æ¨™é¡Œã€åº§æ¨™è»¸è«‹ä½¿ç”¨ä¸­æ–‡ã€‚
                        4. âš ï¸ åš´æ ¼ LaTeX è¦ç¯„ï¼šæ‰€æœ‰åŒ…å« LaTeX èªæ³•çš„å­—ä¸²ï¼ˆå¦‚æ¨™é¡Œã€æ¨™ç±¤ï¼‰ï¼Œ**å¿…é ˆ** ä½¿ç”¨ Python raw string (ä¾‹å¦‚ r'$y=x^2$')ã€‚
                        5. âš ï¸ é¿å…åœ¨ title ä½¿ç”¨éæ–¼è¤‡é›œçš„ LaTeX (å¦‚ \left, \right)ï¼Œè‹¥å¿…é ˆä½¿ç”¨ï¼Œè«‹ç¢ºä¿èªæ³•å®Œç¾é–‰åˆã€‚
                        6. âš ï¸ 3Dç¹ªåœ–ï¼šè‹¥æ˜¯ç©ºé–“åæ¨™é¡Œï¼Œè«‹å‹™å¿…ä½¿ç”¨ `ax = fig.add_subplot(111, projection='3d')`ã€‚
                        """
                        common_role = f"è§’è‰²ï¼šä½ æ˜¯ Jutorã€‚å¹´ç´šï¼š{selected_grade}ã€‚é¡Œç›®ï¼š{question_target}ã€‚"
                        
                        if selected_grade in ["å°äº”", "å°å…­"]:
                            common_role += "ã€é‡è¦ã€‘å­¸ç”Ÿç‚ºå°ç£åœ‹å°ç”Ÿï¼Œè«‹åš´æ ¼éµå®ˆå°ç£åœ‹å°æ•¸å­¸èª²ç¶±ï¼š1. é¿å…ä½¿ç”¨äºŒå…ƒä¸€æ¬¡è¯ç«‹æ–¹ç¨‹å¼æˆ–éæ–¼æŠ½è±¡çš„ä»£æ•¸ç¬¦è™Ÿ(x,y)ã€‚2. å¤šä½¿ç”¨ã€Œç·šæ®µåœ–ã€ã€ã€ŒåŸºæº–é‡æ¯”è¼ƒé‡ã€æˆ–å…·é«”æ•¸å­—æ¨æ¼”ä¾†è§£é‡‹ã€‚3. èªè¨€è¦æ›´ç™½è©±ã€å…·é«”ã€‚"

                        if mode == "verbal":
                            style = "é¢¨æ ¼ï¼šå¹½é»˜å£èªã€è­¬å–»æ•™å­¸ã€æ­¥é©ŸåŒ–ã€‚"
                        else:
                            style = "é¢¨æ ¼ï¼šç´”ç®—å¼ã€LaTeXã€æ¥µç°¡ã€‚"

                        prompt = f"""
                        {guardrail}
                        {transcription}
                        {formatting}
                        {plotting}
                        {common_role}
                        {style}
                        
                        ã€é¡Œå‹è¾¨è­˜ã€‘è«‹åˆ¤æ–·æ˜¯å¦ç‚ºå¤šé¸é¡Œï¼Œè‹¥æœ‰é¸å‡ºæ‰€æœ‰æ­£ç¢ºé¸é …çš„æŒ‡ä»¤ï¼Œè«‹é€ä¸€æª¢æŸ¥ã€‚

                        ã€è¼¸å‡ºçµæ§‹åš´æ ¼è¦æ±‚ - è«‹ç”¨ `===STEP===` åˆ†éš”ã€‘
                        1. **è§£é¡Œéç¨‹** (ç‚ºäº†é¿å…è³‡è¨Šéè¼‰ï¼Œè«‹å°‡éç¨‹æ‹†è§£ç‚º **4~6 å€‹** çŸ­æ­¥é©Ÿï¼Œæ¯ä¸€æ­¥åªè¬›ä¸€å€‹æ ¸å¿ƒè§€å¿µ)
                        ===STEP===
                        (æ­¥é©Ÿ1...)
                        ===STEP===
                        (æ­¥é©Ÿ2...)
                        ===STEP===
                        ...
                        
                        2. **æœ¬é¡Œç­”æ¡ˆ** (æ¨™é¡Œèˆ‡ç­”æ¡ˆå¿…é ˆåœ¨åŒä¸€å€‹STEP)
                        ### ğŸ’¡ æœ¬é¡Œç­”æ¡ˆ
                        (è«‹åœ¨æ­¤åˆ—å‡ºæœ€çµ‚ç­”æ¡ˆï¼Œå¦‚ x=16 æˆ– x=18)
                        
                        ===STEP===
                        
                        3. **é©—æ”¶é¡é¡Œ** (æ¨™é¡Œèˆ‡é¡Œç›®å¿…é ˆåœ¨åŒä¸€å€‹STEP)
                        ### ğŸ¯ é©—æ”¶é¡é¡Œ
                        (è«‹åœ¨æ­¤è™•ç›´æ¥å‡ºé¡Œï¼ŒåŒ…å«æ‰€æœ‰é¡Œç›®è³‡è¨Š)
                        (è‹¥ç‚ºåœ‹å°ç”Ÿï¼Œè«‹å‡ºæ•¸å­—è¼ƒç°¡å–®ã€è§€å¿µé¡ä¼¼çš„æ‡‰ç”¨é¡Œ)
                        
                        ===STEP===
                        
                        4. **é¡é¡Œç­”æ¡ˆ** (æœ€å¾Œä¸€å€‹STEP)
                        ğŸ—ï¸ é¡é¡Œç­”æ¡ˆ
                        (åƒ…æä¾›æœ€çµ‚ç­”æ¡ˆï¼Œä¸éœ€è©³è§£)
                        """

                        response, key_suffix = call_gemini_with_rotation(prompt, image, use_pro=use_pro)
                        st.session_state.used_key_suffix = key_suffix
                        
                        if "REFUSE_OFF_TOPIC" in response.text:
                            st.error("ğŸ™…â€â™‚ï¸ é€™å€‹å­¸æ ¡å¥½åƒä¸æœƒè€ƒå–”ï¼(è‹¥ç‚ºèª¤åˆ¤ï¼Œè«‹å˜—è©¦è£åˆ‡åœ–ç‰‡)")
                        else:
                            full_text = clean_output_format(response.text)
                            image_desc = "ç„¡æè¿°"
                            desc_match = re.search(r"===DESC===(.*?)===DESC_END===", full_text, re.DOTALL)
                            if desc_match:
                                image_desc = desc_match.group(1).strip()
                                full_text = full_text.replace(desc_match.group(0), "")
                            
                            st.session_state.image_desc_cache = image_desc
                            st.session_state.full_text_cache = full_text

                            plot_code = None
                            plot_match = re.search(r"===PLOT===(.*?)===PLOT_END===", full_text, re.DOTALL)
                            if plot_match:
                                plot_code = plot_match.group(1).strip()
                                plot_code = plot_code.replace("```python", "").replace("```", "")
                                full_text = full_text.replace(plot_match.group(0), "")
                            
                            st.session_state.plot_code = plot_code
                            
                            raw_steps = full_text.split("===STEP===")
                            st.session_state.solution_steps = [step.strip() for step in raw_steps if step.strip()]
                            st.session_state.step_index = 0
                            st.session_state.is_solving = True
                            st.session_state.streaming_done = False
                            st.session_state.in_qa_mode = False
                            st.session_state.qa_history = []
                            st.session_state.data_saved = False
                            st.session_state.is_reporting = False

                            save_to_google_sheets(selected_grade, mode, image_desc, full_text, key_suffix)
                            st.rerun()

                    except Exception as e:
                        if "429" in str(e) or "Quota" in str(e): 
                            st.warning("ğŸ¥µ ç³»çµ±å¿™ç¢Œä¸­...")
                            st.error("è«‹ç¨å€™é‡è©¦ï¼")
                        else: st.error(f"éŒ¯èª¤ï¼š{e}")

if st.session_state.is_solving and st.session_state.solution_steps:
    
    header_text = "ğŸ—£ï¸ Jutor å£èªæ•™å­¸ä¸­" if st.session_state.solve_mode == "verbal" else "ğŸ”¢ ç´”ç®—å¼æ¨å°ä¸­"
    
    if st.session_state.use_pro_model:
        st.markdown(f"### {header_text} (ğŸ”¥ 2.5 Pro æ•‘æ´)")
    else:
        st.markdown(f"### {header_text}") 
    
    if st.session_state.plot_code:
        with st.expander("ğŸ“Š æŸ¥çœ‹å¹¾ä½•/å‡½æ•¸åœ–å½¢", expanded=True):
            execute_and_show_plot(st.session_state.plot_code)

    for i in range(st.session_state.step_index):
        with st.chat_message("assistant", avatar=assistant_avatar):
            st.markdown(st.session_state.solution_steps[i])
            
    current_step_text = st.session_state.solution_steps[st.session_state.step_index]
    with st.chat_message("assistant", avatar=assistant_avatar):
        trigger_vibration()
        st.markdown(current_step_text)

    total_steps = len(st.session_state.solution_steps)
    
    if st.session_state.is_reporting:
        st.markdown("---")
        with st.container(border=True):
            st.markdown("### ğŸš¨ éŒ¯èª¤å›å ±")
            student_comment = st.text_area("è«‹å‘Šè¨´ Jutor å“ªè£¡æ€ªæ€ªçš„ï¼Ÿ(ä¾‹å¦‚ï¼šç¬¬äºŒè¡Œç®—éŒ¯äº†ã€é€™é¡Œç­”æ¡ˆæ‡‰è©²æ˜¯ 100...)", height=100)
            
            c1, c2 = st.columns(2)
            with c1:
                if st.button("å–æ¶ˆ", use_container_width=True):
                    st.session_state.is_reporting = False
                    st.rerun()
            with c2:
                if st.button("ç¢ºèªé€å‡º", type="primary", use_container_width=True):
                    if not student_comment:
                        st.warning("è«‹ç¨å¾®æè¿°ä¸€ä¸‹å•é¡Œå–”ï¼")
                    else:
                        success = send_telegram_alert(
                             selected_grade, 
                             st.session_state.image_desc_cache, 
                             st.session_state.full_text_cache,
                             student_comment
                        )
                        if success:
                            st.session_state.is_reporting = False
                            st.toast("å·²æ”¶åˆ°æ‚¨çš„å›è¦†ï¼Œæˆ‘å€‘æ­£åœ¨è«‹ Jutor æœ¬äººä¸‹å‡¡è™•ç†ï¼Œè«‹å…ˆç¹¼çºŒå¯«åˆ¥é¡Œå§ï¼", icon="ğŸ“¨")
                            st.balloons()
                            time.sleep(2)
                            st.rerun()
                        else:
                            st.error("ç™¼é€å¤±æ•—")

    elif st.session_state.step_index < total_steps - 1:
        if not st.session_state.in_qa_mode:
            st.markdown("---")
            col_back, col_ask, col_next = st.columns([1, 1, 2])
            
            with col_back:
                def prev_step():
                    if st.session_state.step_index > 0:
                        st.session_state.step_index -= 1
                st.button("â¬…ï¸ ä¸Šä¸€æ­¥", on_click=prev_step, disabled=(st.session_state.step_index == 0), use_container_width=True)

            with col_ask:
                def enter_qa_mode():
                    st.session_state.in_qa_mode = True
                    context_prompt = f"è¬›è§£æ­¥é©Ÿï¼š{current_step_text}ã€‚"
                    if st.session_state.solve_mode == "math": context_prompt += "ç›®å‰æ˜¯ç´”ç®—å¼æ¨¡å¼ï¼Œå­¸ç”Ÿä¸æ‡‚ã€‚"
                    st.session_state.qa_history = [{"role": "user", "parts": [context_prompt]}, {"role": "model", "parts": ["è«‹æå•ã€‚"]}]
                st.button("ğŸ¤” æˆ‘æƒ³å•...", on_click=enter_qa_mode, use_container_width=True)

            with col_next:
                btn_label = "âœ… æˆ‘æ‡‚äº†ï¼Œä¸‹ä¸€æ­¥ï¼"
                if st.session_state.step_index == total_steps - 2: 
                    btn_label = "ğŸ‘€ æ ¸å°é¡é¡Œç­”æ¡ˆ"
                
                def next_step():
                    st.session_state.step_index += 1
                st.button(btn_label, on_click=next_step, use_container_width=True, type="primary")

        else:
            with st.container(border=True):
                st.markdown("#### ğŸ’¡ æå•æ™‚é–“")
                for msg in st.session_state.qa_history[2:]:
                      if msg["role"] == "user": 
                          icon = "ğŸ‘¤"
                      else: 
                          icon = assistant_avatar
                      
                      with st.chat_message(msg["role"], avatar=icon):
                          st.markdown(msg["parts"][0])
                          
                user_question = st.chat_input("è«‹è¼¸å…¥å•é¡Œ...")
                if user_question:
                    with st.chat_message("user", avatar="ğŸ‘¤"): st.markdown(user_question)
                    st.session_state.qa_history.append({"role": "user", "parts": [user_question]})
                    
                    with st.chat_message("assistant", avatar=assistant_avatar):
                        with st.spinner("æ€è€ƒä¸­..."):
                            try:
                                full_prompt = "å°è©±ç´€éŒ„:\n" + "\n".join([f"{h['role']}:{h['parts'][0]}" for h in st.session_state.qa_history]) + f"\næ–°å•é¡Œ:{user_question}"
                                response, _ = call_gemini_with_rotation(full_prompt, use_pro=st.session_state.use_pro_model)
                                st.markdown(response.text)
                                st.session_state.qa_history.append({"role": "model", "parts": [response.text]})
                            except: st.error("å¿™ç¢Œä¸­")
                    st.rerun()
                def exit_qa_mode():
                    st.session_state.in_qa_mode = False
                    st.session_state.qa_history = []
                st.button("ğŸ‘Œ å›åˆ°ä¸»æµç¨‹", on_click=exit_qa_mode, use_container_width=True)

    else:
        st.markdown("---")
        st.success("ğŸ‰ æ­å–œå®Œæˆï¼")
        
        col_end_back, col_end_reset = st.columns([1, 2])
        with col_end_back:
            def prev_step_end():
                st.session_state.step_index -= 1
            st.button("â¬…ï¸ ä¸Šä¸€æ­¥", on_click=prev_step_end, use_container_width=True)
        with col_end_reset:
            if st.button("ğŸ”„ é‡æ–°å•åˆ¥é¡Œ", use_container_width=True):
                st.session_state.is_solving = False
                st.session_state.solution_steps = []
                st.session_state.step_index = 0
                st.session_state.in_qa_mode = False
                st.session_state.data_saved = False
                st.session_state.plot_code = None
                st.session_state.use_pro_model = False
                st.session_state.is_reporting = False
                st.rerun()

        st.markdown("")
        st.markdown("---")
        
        if not st.session_state.is_reporting:
            report_col1, report_col2 = st.columns([1, 4])
            with report_col2:
                 if st.button("ğŸš¨ ç­”æ¡ˆæœ‰éŒ¯ï¼Œå›å ±çµ¦é³©ç‰¹", use_container_width=True, type="secondary"):
                     st.session_state.is_reporting = True
                     st.rerun()
