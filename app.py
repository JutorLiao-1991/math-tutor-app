import streamlit as st
import google.generativeai as genai
from PIL import Image
import os
import time
import streamlit.components.v1 as components
import random
import re
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np
import requests

# --- æ³¨å…¥è‡ªå®šç¾© CSS ---
def inject_custom_css():
    st.markdown(
        """
        <style>
        .katex-html { overflow-x: auto; overflow-y: hidden; max-width: 100%; display: block; padding-bottom: 5px; }
        .stMarkdown { max-width: 100%; overflow-wrap: break-word; }
        .stChatMessage .stChatMessageAvatar {
            width: 2.8rem; /* ç¨å¾®æ”¾å¤§ä¸€é»é ­åƒ */
            height: 2.8rem;
            background-color: #f0f2f6; 
            border-radius: 50%; /* è®“é ­åƒè®Šåœ“å½¢ */
            object-fit: cover;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

# --- è‡ªå‹•ä¸‹è¼‰ä¸¦è¨­å®šä¸­æ–‡å­—å‹ ---
def configure_chinese_font():
    font_name = "NotoSansCJKtc-Regular.otf"
    if not os.path.exists(font_name):
        # éœé»˜ä¸‹è¼‰ï¼Œä¸å°å‡ºå¤ªå¤šè¨Šæ¯
        try:
            url = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/TraditionalChinese/NotoSansCJKtc-Regular.otf"
            response = requests.get(url)
            with open(font_name, 'wb') as f:
                f.write(response.content)
        except:
            pass 

    try:
        fm.fontManager.addfont(font_name)
        plt.rcParams['font.family'] = 'Noto Sans CJK TC'
        plt.rcParams['axes.unicode_minus'] = False
    except:
        pass

# --- åœ–ç‰‡èˆ‡é ­åƒè¨­å®šé‚è¼¯ ---
# 1. ç¶²ç«™ä¸» Logo (é¡¯ç¤ºåœ¨å·¦ä¸Šè§’)
main_logo_path = "logo.jpg"
if os.path.exists(main_logo_path):
    page_icon_set = Image.open(main_logo_path)
else:
    page_icon_set = "ğŸ¦"

# 2. åŠ©æ‰‹å°è©±é ­åƒ (é¡¯ç¤ºåœ¨å°è©±æ¡†)
# å„ªå…ˆæ‰¾ avatar.jpg -> å…¶æ¬¡æ‰¾ logo.jpg -> æœ€å¾Œç”¨ Emoji
avatar_file_path = "avatar.jpg" 

if os.path.exists(avatar_file_path):
    assistant_avatar = avatar_file_path
elif os.path.exists(main_logo_path):
    assistant_avatar = main_logo_path
else:
    assistant_avatar = "ğŸ¦"

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI é³©ç‰¹è§£é¡Œ v4.6", page_icon=page_icon_set, layout="centered")
inject_custom_css()
configure_chinese_font()

# --- åˆå§‹åŒ– Session State ---
if 'step_index' not in st.session_state: st.session_state.step_index = 0
if 'solution_steps' not in st.session_state: st.session_state.solution_steps = []
if 'is_solving' not in st.session_state: st.session_state.is_solving = False
if 'streaming_done' not in st.session_state: st.session_state.streaming_done = False
if 'in_qa_mode' not in st.session_state: st.session_state.in_qa_mode = False
if 'qa_history' not in st.session_state: st.session_state.qa_history = []
if 'solve_mode' not in st.session_state: st.session_state.solve_mode = "verbal"
if 'data_saved' not in st.session_state: st.session_state.data_saved = False
if 'plot_code' not in st.session_state: st.session_state.plot_code = None
if 'use_pro_model' not in st.session_state: st.session_state.use_pro_model = False

# --- å‡½æ•¸å€ ---
def stream_text(text):
    for char in text:
        yield char
        time.sleep(0.02)

def trigger_vibration():
    vibrate_js = """<script>if(navigator.vibrate){navigator.vibrate(30);}</script>"""
    components.html(vibrate_js, height=0, width=0)

def save_to_google_sheets(grade, mode, image_desc, full_response):
    try:
        if "gcp_service_account" in st.secrets:
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            creds_dict = dict(st.secrets["gcp_service_account"])
            creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
            creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(creds)
            sheet = client.open("Jutor_Learning_Data").sheet1
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            sheet.append_row([timestamp, grade, mode, image_desc, full_response])
            return True
    except Exception as e:
        print(f"å­˜æª”å¤±æ•—: {e}")
        return False

def execute_and_show_plot(code_snippet):
    try:
        # é‡è¨­å­—å‹ç¢ºä¿ä¸­æ–‡æ­£å¸¸
        plt.rcParams['font.family'] = 'Noto Sans CJK TC'
        plt.rcParams['axes.unicode_minus'] = False
        
        plt.figure(figsize=(6, 4))
        plt.style.use('seaborn-v0_8-whitegrid') 
        local_scope = {'plt': plt, 'np': np}
        exec(code_snippet, globals(), local_scope)
        st.pyplot(plt)
        plt.close()
    except Exception as e:
        st.warning(f"åœ–å½¢ç¹ªè£½å¤±æ•—: {e}")

def call_gemini_with_rotation(prompt_content, image_input=None, use_pro=False):
    try:
        keys = st.secrets["API_KEYS"]
        if isinstance(keys, str): keys = [keys]
    except:
        st.error("API_KEYS è¨­å®šéŒ¯èª¤")
        st.stop()
    
    shuffled_keys = keys.copy()
    random.shuffle(shuffled_keys)
    
    # Flash: 2.5-flash
    # Pro: 2.5-pro
    model_name = 'models/gemini-2.5-pro' if use_pro else 'models/gemini-2.5-flash'
    
    last_error = None
    
    for key in shuffled_keys:
        try:
            genai.configure(api_key=key)
            model = genai.GenerativeModel(model_name)
            if image_input:
                response = model.generate_content([prompt_content, image_input])
            else:
                response = model.generate_content(prompt_content)
            return response
        except Exception as e:
            if "429" in str(e) or "Quota" in str(e) or "503" in str(e):
                last_error = e
                continue
            else:
                raise e
    raise last_error

# ================= ä»‹é¢è¨­è¨ˆ =================

col1, col2 = st.columns([1, 4]) 
with col1:
    # é€™è£¡å§‹çµ‚é¡¯ç¤ºä¸» Logo
    if os.path.exists(main_logo_path): 
        st.image(main_logo_path, use_column_width=True)
    else: 
        st.markdown("<h1 style='text-align: center;'>é³©</h1>", unsafe_allow_html=True)
with col2:
    st.title("é³©ç‰¹æ•¸ç†ï¼¡ï¼©å°å¹«æ‰‹")
    st.caption("AI é³©ç‰¹è§£é¡Œ v4.6 (ç¨ç«‹é ­åƒç‰ˆ)")

st.markdown("---")
col_grade_label, col_grade_select = st.columns([2, 3])
with col_grade_label:
    st.markdown("### ğŸ“‹ è«‹å…ˆé¸æ“‡å¹´ç´šï¼š")
    st.caption("Jutor æœƒä¾æ­¤èª¿æ•´è¬›è§£å£å»ã€‚")
with col_grade_select:
    selected_grade = st.selectbox("å¹´ç´š", ("åœ‹ä¸€", "åœ‹äºŒ", "åœ‹ä¸‰", "é«˜ä¸€", "é«˜äºŒ", "é«˜ä¸‰"), label_visibility="collapsed")
st.markdown("---")

# --- ä¸Šå‚³å€ ---
if not st.session_state.is_solving:
    st.subheader("ğŸ“¸ 1ï¸âƒ£ ä¸Šå‚³é¡Œç›® & æŒ‡å®š")
    uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡ (JPG, PNG)", type=["jpg", "png", "jpeg"], label_visibility="collapsed")

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='é¡Œç›®é è¦½', use_column_width=True)
        question_target = st.text_input("ä½ æƒ³å•åœ–ç‰‡ä¸­çš„å“ªä¸€é¡Œï¼Ÿ", placeholder="ä¾‹å¦‚ï¼šç¬¬ 5 é¡Œ...")
        
        use_pro = st.checkbox("ğŸ”¥ å•Ÿç”¨ 2.5 Pro æ·±åº¦æ€è€ƒ (é©åˆé›£é¡Œæˆ– Flash è§£éŒ¯æ™‚)", value=False)
        
        st.markdown("### ğŸš€ é¸æ“‡è§£é¡Œæ¨¡å¼ï¼š")
        col_btn_verbal, col_btn_math = st.columns(2)
        with col_btn_verbal:
            start_verbal = st.button("ğŸ—£ï¸ Jutor å£èªæ•™å­¸", use_container_width=True, type="primary")
        with col_btn_math:
            start_math = st.button("ğŸ”¢ ç´”ç®—å¼è§£æ³•", use_container_width=True)

        if start_verbal or start_math:
            if not question_target:
                st.warning("âš ï¸ è«‹å…ˆè¼¸å…¥ä½ æƒ³å•å“ªä¸€é¡Œï¼")
            else:
                mode = "verbal" if start_verbal else "math"
                st.session_state.solve_mode = mode
                st.session_state.use_pro_model = use_pro
                
                engine_name = "Jutor 2.5 Pro" if use_pro else "Jutor 2.5 Flash"
                loading_text = f"{engine_name} æ­£åœ¨å•Ÿå‹•ç¹ªåœ–å¼•æ“èˆ‡åˆ†æ..."
                
                with st.spinner(loading_text):
                    try:
                        guardrail = "ã€æœ€é«˜é˜²è­·ã€‘éèª²æ¥­ç›¸é—œ(è‡ªæ‹/é¢¨æ™¯)è«‹å›å‚³: REFUSE_OFF_TOPIC"
                        transcription = f"ã€éš±è—ä»»å‹™ã€‘å°‡é¡Œç›® '{question_target}' è½‰è­¯ç‚ºæ–‡å­—ï¼Œä¸¦å°‡å¹¾ä½•ç‰¹å¾µè½‰ç‚ºæ–‡å­—æè¿°ï¼ŒåŒ…åœ¨ `===DESC===` èˆ‡ `===DESC_END===` ä¹‹é–“ã€‚"
                        formatting = "ã€æ’ç‰ˆã€‘æ–‡å­—ç®—å¼åˆ†è¡Œã€‚é•·ç®—å¼ç”¨ `\\\\` æ›è¡Œã€‚"
                        plotting = """
                        ã€ç¹ªåœ–èƒ½åŠ›å•Ÿå‹•ã€‘
                        å¦‚æœé¡Œç›®æ¶‰åŠã€Œå‡½æ•¸åœ–å½¢ã€æˆ–ã€Œå¹¾ä½•åº§æ¨™ã€ï¼Œè«‹ç”¢ç”Ÿ Python ç¨‹å¼ç¢¼ (matplotlib + numpy)ã€‚
                        1. ç¨‹å¼ç¢¼å¿…é ˆèƒ½ç›´æ¥åŸ·è¡Œã€‚
                        2. å¿…é ˆåŒ…åœ¨ `===PLOT===` èˆ‡ `===PLOT_END===` ä¹‹é–“ã€‚
                        3. åœ–è¡¨æ¨™é¡Œã€åº§æ¨™è»¸è‹¥æœ‰ä¸­æ–‡ï¼Œè«‹ç›´æ¥ä½¿ç”¨ä¸­æ–‡(ä¸ç”¨æ“”å¿ƒå­—å‹å•é¡Œï¼Œå¾Œå°å·²è¨­å®šå¥½)ã€‚
                        """

                        common_role = f"è§’è‰²ï¼šä½ æ˜¯ Jutorã€‚å¹´ç´šï¼š{selected_grade}ã€‚é¡Œç›®ï¼š{question_target}ã€‚"
                        if mode == "verbal":
                            style = "é¢¨æ ¼ï¼šå¹½é»˜å£èªã€è­¬å–»æ•™å­¸ã€æ­¥é©ŸåŒ–ã€‚"
                        else:
                            style = "é¢¨æ ¼ï¼šç´”ç®—å¼ã€LaTeXã€æ¥µç°¡ã€‚"

                        prompt = f"""
                        {guardrail}
                        {transcription}
                        {formatting}
                        {plotting}
                        {common_role}
                        {style}

                        çµæ§‹è¦æ±‚ï¼š
                        (æè¿°) ===DESC=== ... ===DESC_END===
                        (ç¹ªåœ–-é¸ç”¨) ===PLOT=== python code ===PLOT_END===
                        (è§£é¡Œ)
                        ç¢ºèªé¡Œç›® ===STEP===
                        è§£é¡Œéç¨‹(æ¯ä¸€æ­¥STEPåˆ†éš”) ===STEP===
                        ...
                        æœ¬é¡Œç­”æ¡ˆ ===STEP=== ã€é©—æ”¶é¡é¡Œã€‘ ===STEP=== ã€é¡é¡Œè©³è§£ã€‘
                        """

                        response = call_gemini_with_rotation(prompt, image, use_pro=use_pro)
                        
                        if "REFUSE_OFF_TOPIC" in response.text:
                            st.error("ğŸ™…â€â™‚ï¸ é€™å€‹å­¸æ ¡å¥½åƒä¸æœƒè€ƒå–”ï¼")
                        else:
                            full_text = response.text
                            image_desc = "ç„¡æè¿°"
                            desc_match = re.search(r"===DESC===(.*?)===DESC_END===", full_text, re.DOTALL)
                            if desc_match:
                                image_desc = desc_match.group(1).strip()
                                full_text = full_text.replace(desc_match.group(0), "")

                            plot_code = None
                            plot_match = re.search(r"===PLOT===(.*?)===PLOT_END===", full_text, re.DOTALL)
                            if plot_match:
                                plot_code = plot_match.group(1).strip()
                                plot_code = plot_code.replace("```python", "").replace("```", "")
                                full_text = full_text.replace(plot_match.group(0), "")
                            
                            st.session_state.plot_code = plot_code
                            
                            raw_steps = full_text.split("===STEP===")
                            st.session_state.solution_steps = [step.strip() for step in raw_steps if step.strip()]
                            st.session_state.step_index = 0
                            st.session_state.is_solving = True
                            st.session_state.streaming_done = False
                            st.session_state.in_qa_mode = False
                            st.session_state.qa_history = []
                            st.session_state.data_saved = False

                            save_to_google_sheets(selected_grade, mode, image_desc, full_text)
                            st.rerun()

                    except Exception as e:
                        if "429" in str(e) or "Quota" in str(e): 
                            st.warning("ğŸ¥µ ç³»çµ±å¿™ç¢Œä¸­...")
                            st.error("è«‹ç¨å€™é‡è©¦ï¼")
                        else: st.error(f"éŒ¯èª¤ï¼š{e}")

# ================= è§£é¡Œäº’å‹• =================

if st.session_state.is_solving and st.session_state.solution_steps:
    
    header_text = "ğŸ—£ï¸ Jutor å£èªæ•™å­¸ä¸­" if st.session_state.solve_mode == "verbal" else "ğŸ”¢ ç´”ç®—å¼æ¨å°ä¸­"
    if st.session_state.use_pro_model:
        header_text += " (ğŸ”¥ 2.5 Pro)"
    st.subheader(header_text)
    
    if st.session_state.plot_code:
        with st.expander("ğŸ“Š æŸ¥çœ‹å¹¾ä½•/å‡½æ•¸åœ–å½¢ (AI ç¹ªè£½)", expanded=True):
            execute_and_show_plot(st.session_state.plot_code)

    for i in range(st.session_state.step_index):
        # é€™è£¡æœƒè®€å–æ–°çš„ avatar.jpg
        with st.chat_message("assistant", avatar=assistant_avatar):
            st.markdown(st.session_state.solution_steps[i])
            
    current_step_text = st.session_state.solution_steps[st.session_state.step_index]
    with st.chat_message("assistant", avatar=assistant_avatar):
        if not st.session_state.streaming_done:
            trigger_vibration()
            st.write_stream(stream_text(current_step_text))
            st.session_state.streaming_done = True
        else:
            st.markdown(current_step_text)

    total_steps = len(st.session_state.solution_steps)
    if st.session_state.step_index < total_steps - 1:
        if not st.session_state.in_qa_mode:
            st.markdown("---")
            col_back, col_ask, col_next = st.columns([1, 1, 2])
            
            with col_back:
                def prev_step():
                    if st.session_state.step_index > 0:
                        st.session_state.step_index -= 1
                        st.session_state.streaming_done = True 
                st.button("â¬…ï¸ ä¸Šä¸€æ­¥", on_click=prev_step, disabled=(st.session_state.step_index == 0), use_container_width=True)

            with col_ask:
                def enter_qa_mode():
                    st.session_state.in_qa_mode = True
                    context_prompt = f"è¬›è§£æ­¥é©Ÿï¼š{current_step_text}ã€‚"
                    if st.session_state.solve_mode == "math": context_prompt += "ç›®å‰æ˜¯ç´”ç®—å¼æ¨¡å¼ï¼Œå­¸ç”Ÿä¸æ‡‚ã€‚"
                    st.session_state.qa_history = [{"role": "user", "parts": [context_prompt]}, {"role": "model", "parts": ["è«‹æå•ã€‚"]}]
                st.button("ğŸ¤” æˆ‘æƒ³å•...", on_click=enter_qa_mode, use_container_width=True)

            with col_next:
                btn_label = "âœ… æˆ‘æ‡‚äº†ï¼Œä¸‹ä¸€æ­¥ï¼"
                if st.session_state.step_index == total_steps - 2: btn_label = "ğŸ‘€ æ ¸å°é¡é¡Œç­”æ¡ˆ"
                def next_step():
                    st.session_state.step_index += 1
                    st.session_state.streaming_done = False
                st.button(btn_label, on_click=next_step, use_container_width=True, type="primary")

        else:
            with st.container(border=True):
                st.markdown("#### ğŸ’¡ æå•æ™‚é–“")
                for msg in st.session_state.qa_history[2:]:
                     if msg["role"] == "user": 
                         icon = "ğŸ‘¤"
                     else: 
                         # é€™è£¡ä¹Ÿæœƒè®€å–æ–°çš„ avatar.jpg
                         icon = assistant_avatar
                     
                     with st.chat_message(msg["role"], avatar=icon):
                         st.markdown(msg["parts"][0])
                         
                user_question = st.chat_input("è«‹è¼¸å…¥å•é¡Œ...")
                if user_question:
                    with st.chat_message("user", avatar="ğŸ‘¤"): st.markdown(user_question)
                    st.session_state.qa_history.append({"role": "user", "parts": [user_question]})
                    
                    with st.chat_message("assistant", avatar=assistant_avatar):
                        with st.spinner("æ€è€ƒä¸­..."):
                            try:
                                full_prompt = "å°è©±ç´€éŒ„:\n" + "\n".join([f"{h['role']}:{h['parts'][0]}" for h in st.session_state.qa_history]) + f"\næ–°å•é¡Œ:{user_question}"
                                response = call_gemini_with_rotation(full_prompt, use_pro=st.session_state.use_pro_model)
                                st.write_stream(stream_text(response.text))
                                st.session_state.qa_history.append({"role": "model", "parts": [response.text]})
                            except: st.error("å¿™ç¢Œä¸­")
                    st.rerun()
                def exit_qa_mode():
                    st.session_state.in_qa_mode = False
                    st.session_state.qa_history = []
                st.button("ğŸ‘Œ å›åˆ°ä¸»æµç¨‹", on_click=exit_qa_mode, use_container_width=True)

    else:
        st.markdown("---")
        st.success("ğŸ‰ æ­å–œå®Œæˆï¼")
        col_end_back, col_end_reset = st.columns([1, 2])
        with col_end_back:
            def prev_step_end():
                st.session_state.step_index -= 1
                st.session_state.streaming_done = True
            st.button("â¬…ï¸ ä¸Šä¸€æ­¥", on_click=prev_step_end, use_container_width=True)
        with col_end_reset:
            if st.button("ğŸ”„ é‡æ–°å•åˆ¥é¡Œ", use_container_width=True):
                st.session_state.is_solving = False
                st.session_state.solution_steps = []
                st.session_state.step_index = 0
                st.session_state.streaming_done = False
                st.session_state.in_qa_mode = False
                st.session_state.data_saved = False
                st.session_state.plot_code = None
                st.session_state.use_pro_model = False
                st.rerun()
